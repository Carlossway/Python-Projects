{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring and Preparing Data for Analysis\n",
    "\n",
    "In this notebook, we’ll guide you through the fundamental steps of working with a dataset.\n",
    "\n",
    "By the end of this notebook, you will be able to perform basic exploratory data analysis (EDA) to uncover patterns and insights.\n",
    "\n",
    "The dataset we’ll be working with represents sales data from an online retail store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../data/sales_data.csv')  # Example dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the Data with .head()\n",
    "Let’s preview the first few rows with `.head()`. \n",
    "\n",
    "In Pandas it defaults to displaying the first 5 rows of the dataset.\n",
    "\n",
    "However, you can specify a different number of rows by passing an integer as an argument to `.head()`.\n",
    "\n",
    "For example: `data.head(10)` will display the first 10 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the Structure with .info()\n",
    "We inspect the structure of the dataset with `.info()`.\n",
    "\n",
    "There are no missing values in any columns (Non-Null Count matches total rows).\n",
    "`Sales` is an integer type (`int64`), `Cost` is a float type (`float64`), while `Region`, `Product`, and `Date` are object types.\n",
    "\n",
    "Pandas treats any non-numeric data as an object by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the structure with info()\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you know the Region column is meant to be text, you can explicitly convert it to a string data type using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Region to string\n",
    "data['Region'] = data['Region'].astype('string')\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Statistics with .describe()\n",
    "\n",
    "These statistics help us identify outliers and understand data ranges.\n",
    "\n",
    "The `count` value represents the number of non-missing (non-NaN) entries in each column.\n",
    "- `Count` for `Sales` is 10, because there are no non-missing values.\n",
    "- The `maximum sales` value (600) is significantly higher than the minimum value (50), suggesting possible outliers.\n",
    "- The `mean` (325) is close to the `median` (50th percentile = 325), indicating a relatively balanced distribution for this small dataset.\n",
    "\n",
    "Remember, an unbalanced distribution skews results: the `mean` may not reflect typical values, `outliers` can distort analysis, and machine learning models might struggle. \n",
    "\n",
    "Further analysis might confirm whether the high (600) or low (50) values are genuine or anomalies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate statistics\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Month from a Date Column\n",
    "Let’s start by extracting the month from the `Date` column. \n",
    "\n",
    "This helps us identify trends based on the time of year. \n",
    "\n",
    "For example, do certain months see higher sales?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date column to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'], errors='coerce')\n",
    "\n",
    "# Extract the month\n",
    "data['Month'] = data['Date'].dt.month_name()\n",
    "print(data[['Date', 'Month']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising Sales Data\n",
    "Next, let’s normalise the `Sales` data using Min-Max scaling. \n",
    "\n",
    "Normalisation is useful when we want to compare columns with different ranges or prepare data for machine-learning models.\n",
    "\n",
    "This transforms Sales to a range between 0 and 1, where:\n",
    "- 0 represents the minimum sales value.\n",
    "- 1 represents the maximum sales value.\n",
    "- All other sales values are scaled proportionally between 0 and 1.\n",
    "\n",
    "It makes data easier to compare or use in machine learning models, especially when ranges are vastly different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the Sales column\n",
    "data['Normalised_Sales'] = (data['Sales'] - data['Sales'].min()) / (data['Sales'].max() - data['Sales'].min())\n",
    "print(data[['Sales', 'Normalised_Sales']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Profit\n",
    "Let’s calculate Profit for each transaction using the formula:\n",
    "\n",
    "Profit = Sales − Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Profit\n",
    "data['Profit'] = data['Sales'] - data['Cost']\n",
    "print(data[['Sales', 'Cost', 'Profit']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize Sales into Tiers\n",
    "Now, let’s categorise sales into 'High' and 'Low' tiers. \n",
    "\n",
    "We’ll use a threshold of 300 for this activity:\n",
    "- Sales > 300 → High\n",
    "- Sales ≤ 300 → Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize Sales into Tiers\n",
    "data['Sales_Tier'] = ['High' if sale > 300 else 'Low' for sale in data['Sales']]\n",
    "print(data[['Sales', 'Cost', 'Region', 'Sales_Tier']])\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram for Distribution Analysis\n",
    "A histogram shows how Sales values are distributed. \n",
    "\n",
    "It helps answer questions like:\n",
    "\n",
    "- Are most sales concentrated in a specific range?\n",
    "- Are there many low-value or high-value sales?\n",
    "- Are there outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting a histogram\n",
    "plt.hist(data['Sales'], bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Sales Distribution')\n",
    "plt.xlabel('Sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bins\n",
    "In the context of a histogram, bin refers to the intervals into which data is grouped to create the histogram. The number of bins determines how the range of data is divided.\n",
    "\n",
    "If your dataset ranges from 0 to 600 and you set bins=20, the data is divided into 20 equal intervals of size 30.\n",
    "\n",
    "Bin Width = 600/20 = 30\n",
    "\n",
    "The bins will be:\n",
    "- `Bin 1:` 0–30\n",
    "- `Bin 2:` 30–60\n",
    "- `Bin 3`: 60–90\n",
    "- ... and so on, up to `Bin 20:` 570–600.\n",
    "\n",
    "**Why Does the Number of Bins Matter?**\n",
    "- `Too Few Bins:` Oversimplifies data, hiding patterns.\n",
    "- `Too Many Bins:` Overcomplicates the histogram, making it hard to interpret.\n",
    "- `Balanced Bins:` Provides enough detail to reveal patterns without overwhelming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot for Relationships\n",
    "A scatter plot visualizes the relationship between two variables. In this case, Sales and Cost. \n",
    "\n",
    "It helps answer:\n",
    "\n",
    "- Does higher Sales always lead to higher Costs?\n",
    "- Are there transactions where Sales are high but Costs are low (indicating high efficiency)?\n",
    "- Are there outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot comparing Sales and Cost\n",
    "plt.scatter(data['Sales'], data['Cost'], alpha=0.6, color='green')\n",
    "plt.title('Sales vs Cost')\n",
    "plt.xlabel('Sales')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairplot for Variable Correlations (using Seaborn)\n",
    "A pairplot is a grid of scatter plots that shows relationships between multiple numerical variables (e.g., Sales, Cost). \n",
    "\n",
    "It helps:\n",
    "- Identify correlated variables.\n",
    "- Highlight unusual patterns or clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Creating a pairplot for numerical columns\n",
    "sns.pairplot(data[['Sales', 'Cost']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What You See:**\n",
    "- **Diagonal (Histograms):** These show the distribution of individual variables:\n",
    "    - `Sales:` The histogram reveals the range and frequency of sales values.\n",
    "    - `Cost:` The histogram shows the distribution of costs.\n",
    "- **Off-Diagonal (Scatter Plots):** These show how Sales and Cost relate:\n",
    "    - If the points align closely in an upward or downward trend, it indicates a correlation.\n",
    "    - Patterns or clusters may suggest groups in your data or unusual behaviour.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
